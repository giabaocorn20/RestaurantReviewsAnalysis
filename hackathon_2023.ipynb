{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-search-results cohere pandas numpy sklearn matplotlib ntlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6ab73-b831-4e09-afdd-3e9633c272f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import cohere\n",
    "from cohere.responses.classify import Example\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70f998-f309-45de-b7f5-886c3ba0f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_key = ''\n",
    "place_id = \" \"\n",
    "serp_key = \" \"\n",
    "co = cohere.Client(cohere_key)\n",
    "params = {\n",
    "  \"engine\": \" \",\n",
    "  \"place_id\": place_id,\n",
    "  \"api_key\": serp_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711e79d-32f1-4c02-a2d4-2c218366d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('a1_restaurantReviews_HistoricDump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0f6e4-d02c-4d97-8c03-2cf00a2c9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"Negative\", 1: \"Positive\"}  \n",
    "training_data[\"Liked\"] = training_data[\"Liked\"].replace(mapping)\n",
    "#append the data to an examples\n",
    "examples = []\n",
    "for index, row in training_data.iterrows():\n",
    "    example = Example(row[\"Review\"], row[\"Liked\"])\n",
    "    examples.append(example)\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb4cf-0005-401e-865c-850b111113ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for the reviews (serp api)\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "reviews = results[\"reviews\"]\n",
    "#append the review to review array\n",
    "reviews_array = []\n",
    "for user_data in reviews:\n",
    "    comment_text = user_data['comment']['text']\n",
    "    reviews_array.append(comment_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351144d3-3a3a-4d5b-a140-60c42dbdcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = co.classify(\n",
    "  inputs=reviews_array,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "reviews_dict = {\"text\": [], \"sentiment\": [], \"confidence\": []}\n",
    "for data in response_1.classifications:\n",
    "    text = data.input\n",
    "    sentiment = data.prediction\n",
    "    confidence = data.confidence*100\n",
    "    review_dict = {\"text\": text, \"sentiment\": sentiment, \"confidence\": confidence}\n",
    "    reviews_dict[\"text\"].append(text)\n",
    "    reviews_dict[\"sentiment\"].append(sentiment)\n",
    "    reviews_dict[\"confidence\"].append(confidence)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "reviews_sentiment_df = pd.DataFrame(reviews_dict)\n",
    "print(reviews_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b51fc6-d65c-4549-b04f-eb69e2c98b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define a function to extract adjectives and nouns from a text\n",
    "def extract_adj_noun(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    adj_noun = [word for word, tag in pos_tags if tag in ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS']]\n",
    "    return ' '.join(adj_noun)\n",
    "\n",
    "# Apply the function to the review text column\n",
    "reviews_sentiment_df['adj_noun'] = reviews_sentiment_df['text'].apply(extract_adj_noun)\n",
    "print(reviews_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c2c43-e2df-4a47-ad9e-cc7dbd21343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer object and fit it to the adj_noun column\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(reviews_sentiment_df['adj_noun'])\n",
    "\n",
    "# Transform the adj_noun column into a sparse matrix of term frequencies\n",
    "vector = vectorizer.transform(reviews_sentiment_df['adj_noun'])\n",
    "\n",
    "# Print the matrix\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97388b47-55e3-4934-bd34-d3fb17557611",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sentiment_df['sentiment'].value_counts().plot.pie(figsize=(6,6),title=\"Distribution of reviews per sentiment\",labels=['',''],autopct='%1.1f%%')\n",
    "labels=[\"Positive\",\"Negative\"]\n",
    "plt.legend(labels,loc=3)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba19da-2163-4643-b676-f0afff68d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = reviews_sentiment_df['text']\n",
    "y = reviews_sentiment_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector,y,test_size = 0.2)\n",
    "\n",
    "print(y_train)\n",
    "plt.pie(y_train.value_counts(), \n",
    "        labels=['Negative Review','Positive Review'], \n",
    "        autopct='%0.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title(\"Vector data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4024b00-9fbc-42d2-ba6b-b4ebd944470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews = []\n",
    "good_reviews = []\n",
    "\n",
    "for data in response_1.classifications:\n",
    "  if float(data.confidence) > 0.6:\n",
    "    if data.prediction == \"Positive\":\n",
    "      good_reviews.append(data.input)\n",
    "    if data.prediction == \"Negative\":\n",
    "      bad_reviews.append(data.input)\n",
    "\n",
    "#join the string\n",
    "bad_reviews_string = \" \".join(bad_reviews)\n",
    "good_reviews_string = \" \".join(good_reviews)\n",
    "#this is for the reviews  \n",
    "text=(\n",
    "  bad_reviews_string\n",
    ")\n",
    "#what most of the good/bad repsonse talk about \n",
    "response_2 = co.summarize(\n",
    "  text=text,\n",
    "  length=\"short\",\n",
    "  extractiveness=\"high\",\n",
    "  format=\"bullets\",\n",
    "  additional_command=\"give only keywords\"\n",
    ")\n",
    "\n",
    "prompt1 = \"get key words from the text: \" + bad_reviews_string\n",
    "prompt2 = \"get key words from the text: \" + good_reviews_string\n",
    "# model = co.topic_modeling(good_reviews)\n",
    "# print(model.topics)\n",
    "advice1 = co.generate(\n",
    "    model='command-nightly',  \n",
    "    prompt = prompt1,  \n",
    "    max_tokens=200,  \n",
    "    temperature=0.750)\n",
    "advice2 = co.generate(\n",
    "    model='command-nightly',  \n",
    "    prompt = prompt2,  \n",
    "    max_tokens=200,  \n",
    "    temperature=0.750)\n",
    "print(\"Bad reviews keywords\\n\")\n",
    "print(advice1.generations[0])\n",
    "print(\"\\n\")\n",
    "print(\"Good reviews keywords\\n\")\n",
    "print(advice2.generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf2b1d-8ec6-4fc9-a24f-df51aa1b3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d480c-daab-435c-be31-c3f101b3c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6254e-b516-478d-874e-f26098f5f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model + SMOTE\n",
    "logreg = LogisticRegression()\n",
    "# train model on  vectorised training data\n",
    "model = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd697f-a747-42ca-8783-21b442d0a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(model, X_train, feature_names=vectorizer.get_feature_names_out())\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32716f7-f578-4e65-95b2-461108f6dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values,max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356006e1-5530-47ac-ab76-0a0d10ce8f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
